{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN - CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import tensorflow as tf;\n",
    "import numpy as np;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 - Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "#Import csv\n",
    "#assign dependent and independent variables\n",
    "#Check for missing data in the dataset\n",
    "\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Data \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder;\n",
    "#Gender is label encoded because there is a relationship in this column (male/female)\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "\n",
    "\n",
    "#Geographical colunm is encoded using OneHotEncoding because there is no relationship between the points\n",
    "from sklearn.compose import ColumnTransformer;\n",
    "from sklearn.preprocessing import OneHotEncoder;\n",
    "\n",
    "ct = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [1])], remainder=\"passthrough\")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the training and test sets\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling - standardization is used\n",
    "from sklearn.preprocessing import StandardScaler;\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#NO FITTING ON TEST TO AVOID INFORMATION LEAKAGE!!!\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2 - BUILDING THE ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Build the ann\n",
    "\n",
    "#init the artifical neural network \n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "#The input layer is taken from the features (columns) in x\n",
    "\n",
    "#Hidden layer 1 - number of neurons is up for experimentation.\n",
    "ann.add(tf.keras.layers.Dense(6, activation=\"relu\"))\n",
    "\n",
    "#Hidden layer 2 - number of neurons is up for experimentation.\n",
    "ann.add(tf.keras.layers.Dense(6, activation=\"relu\"))\n",
    "\n",
    "#Output layer - number of neurons corresponds to the number of output Columns 1 in this case\n",
    "#output activation function - binary (2, classification): 'sigmoid', non-binary (>2, classification):'softmax', regression: NO ACTIVATION FUNC\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3 - Training the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Compile the ANN---\n",
    "#Optimizer should perform stochastic gradient descent - 'adam' is a good choice. Remember rolling ball\n",
    "#The optimizer updates the weight to reduce the loss error between the prediction and real result.\n",
    "#loss - binary: 'binary_crossentropy', non_binary: 'categorical_crossentropy'\n",
    "ann.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5821\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7945\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7972\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8133\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8166\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8217\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8213\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8231\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8256\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8307\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8418\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8455\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8490\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8490\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8525\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8525\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8522\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8526\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8541\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8547\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8562\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8565\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8585\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8559\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8580\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8574\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8576\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8576\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8569\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8580\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8577\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.8579\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8580\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8585\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8585\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8590\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8576\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8560\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8572\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8597\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8581\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8586\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8565\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8577\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8574\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8580\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8581\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8564\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8574\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95f8b21ae0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--Train the ANN---\n",
    "#batch_size - number of compared items during training. Default/Recommended 32.\n",
    "ann.fit(X_train, y_train, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 4 - Making predictions/evaluating the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "#IMPORTANT - USE THE SAME SCALING AS ABOVE, USE SAME HOT ENCODING\n",
    "#observation in double brackets - 2d array\n",
    "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]])) > 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
